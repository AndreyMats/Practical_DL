{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e85584c419aa445285eecb482778c7ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5694548560b548dabed4b111766da60e","IPY_MODEL_7fceb5ec7dec415a9dfcd4261aeb4a3d","IPY_MODEL_1fd2361180bd49aa8e2012a5e379d0c1"],"layout":"IPY_MODEL_77441a81d25c40819ae5af99ad70f3c8"}},"5694548560b548dabed4b111766da60e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48c3bc239f16407bbba2d36ac6e5aaae","placeholder":"​","style":"IPY_MODEL_5c87b856ffeb4c1dbf2d4637065d26ef","value":"Downloading (…)lve/main/config.json: 100%"}},"7fceb5ec7dec415a9dfcd4261aeb4a3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbbe93e1d4a5493782b7a246f3cb1760","max":629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3e31f6d90a84af08ee33023be184849","value":629}},"1fd2361180bd49aa8e2012a5e379d0c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6099e17176dd4eef829ac7c45badc9e2","placeholder":"​","style":"IPY_MODEL_7ea9a125c76543419007fd5083ed63cd","value":" 629/629 [00:00&lt;00:00, 12.4kB/s]"}},"77441a81d25c40819ae5af99ad70f3c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48c3bc239f16407bbba2d36ac6e5aaae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c87b856ffeb4c1dbf2d4637065d26ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbbe93e1d4a5493782b7a246f3cb1760":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3e31f6d90a84af08ee33023be184849":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6099e17176dd4eef829ac7c45badc9e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ea9a125c76543419007fd5083ed63cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2786e8af69e490cba5048fca7a0a51e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f07e54fd856f4efc99bedb44abcece1b","IPY_MODEL_e0d2ca01fd7042a88a5493323a61409c","IPY_MODEL_e07d888d412d43f8ac4cc5285de07772"],"layout":"IPY_MODEL_15227ca6cc5a4d219e0113da09926da4"}},"f07e54fd856f4efc99bedb44abcece1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf83aaa31a1a47419db2127456beae69","placeholder":"​","style":"IPY_MODEL_1e463fce356b46859493cbd975163ef1","value":"Downloading model.safetensors: 100%"}},"e0d2ca01fd7042a88a5493323a61409c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ecb5a9efc3c42dd8faf4af9424ad5cf","max":267832558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3af4702b95484b8cabd891b18ffc71b1","value":267832558}},"e07d888d412d43f8ac4cc5285de07772":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9210c257b8a4091b86123271c8a5486","placeholder":"​","style":"IPY_MODEL_7eb0bf256b8d4975b0615aa96f00bbe1","value":" 268M/268M [00:01&lt;00:00, 172MB/s]"}},"15227ca6cc5a4d219e0113da09926da4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf83aaa31a1a47419db2127456beae69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e463fce356b46859493cbd975163ef1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ecb5a9efc3c42dd8faf4af9424ad5cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3af4702b95484b8cabd891b18ffc71b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9210c257b8a4091b86123271c8a5486":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eb0bf256b8d4975b0615aa96f00bbe1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc132bfb7d6447ad9900af7b80806aa1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab6d124394214415a2580983c88bbb11","IPY_MODEL_8578b4d2279f40dc846fcdfc2df55742","IPY_MODEL_7213248ebe1f4e28a00a93eb33169170"],"layout":"IPY_MODEL_b1497c0d7c3b4c04a91302a2cbc96db1"}},"ab6d124394214415a2580983c88bbb11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60e971374e5448d08e9698a5594ff60a","placeholder":"​","style":"IPY_MODEL_6c8113bb76024debaf3256431cbefe35","value":"Downloading (…)okenizer_config.json: 100%"}},"8578b4d2279f40dc846fcdfc2df55742":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_73d8ad019f044a6998e81273a922745a","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a445a35355424cb0b4c7abf3d4e6f32d","value":48}},"7213248ebe1f4e28a00a93eb33169170":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d71a81e25f5b4f88b8361c62e2ab9f44","placeholder":"​","style":"IPY_MODEL_4f084bbe71bb433ba0e7ee50fccb71cc","value":" 48.0/48.0 [00:00&lt;00:00, 1.58kB/s]"}},"b1497c0d7c3b4c04a91302a2cbc96db1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60e971374e5448d08e9698a5594ff60a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c8113bb76024debaf3256431cbefe35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73d8ad019f044a6998e81273a922745a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a445a35355424cb0b4c7abf3d4e6f32d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d71a81e25f5b4f88b8361c62e2ab9f44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f084bbe71bb433ba0e7ee50fccb71cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5cff2bc12fec494e9e19b8a956186df6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_787781c894bd46c6990f2513d9f2c79c","IPY_MODEL_3f4eae6f79054676976f87b9524c4cf5","IPY_MODEL_237d34743ee64428a9d22ee51e0423f3"],"layout":"IPY_MODEL_b095428dcb8a4408854f854de54d5692"}},"787781c894bd46c6990f2513d9f2c79c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b76512711884ffb81d3c3505b8fd137","placeholder":"​","style":"IPY_MODEL_2f53a3d1d0f44192beeb6ed8d40e762f","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"3f4eae6f79054676976f87b9524c4cf5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b194af3033342b0b04dc12b3e055ff2","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_391b8f44109544328617fbc3a3c3b9fc","value":231508}},"237d34743ee64428a9d22ee51e0423f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f36db95f6fb4b4687c7130fc23c4348","placeholder":"​","style":"IPY_MODEL_82a35a7ae5e441a1b66534a3eab5e765","value":" 232k/232k [00:00&lt;00:00, 3.06MB/s]"}},"b095428dcb8a4408854f854de54d5692":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b76512711884ffb81d3c3505b8fd137":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f53a3d1d0f44192beeb6ed8d40e762f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b194af3033342b0b04dc12b3e055ff2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"391b8f44109544328617fbc3a3c3b9fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f36db95f6fb4b4687c7130fc23c4348":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82a35a7ae5e441a1b66534a3eab5e765":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install -q transformers huggingface_hub\nimport math\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"id":"zriTdjauH8iQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e25d0f3f-2879-4d80-8cad-f949cf5b8453","execution":{"iopub.status.busy":"2024-03-04T07:29:08.932398Z","iopub.execute_input":"2024-03-04T07:29:08.933047Z","iopub.status.idle":"2024-03-04T07:29:25.256503Z","shell.execute_reply.started":"2024-03-04T07:29:08.933003Z","shell.execute_reply":"2024-03-04T07:29:25.255475Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Using pre-trained transformers (2 points)\n_for fun and profit_\n\nThere are many toolkits that let you access pre-trained transformer models, but the most powerful and convenient by far is [`huggingface/transformers`](https://github.com/huggingface/transformers). In this week's practice, you'll learn how to download, apply and modify pre-trained transformers for a range of tasks. Buckle up, we're going in!\n\n\n__Pipelines:__ if all you want is to apply a pre-trained model, you can do that in one line of code using pipeline. Huggingface/transformers has a selection of pre-configured pipelines for masked language modelling, sentiment classification, question aswering, etc. ([see full list here](https://huggingface.co/transformers/main_classes/pipelines.html))\n\nA typical pipeline includes:\n* pre-processing, e.g. tokenization, subword segmentation\n* a backbone model, e.g. bert finetuned for classification\n* output post-processing\n\nLet's see it in action:","metadata":{"id":"xQiRPWWHlSgv"}},{"cell_type":"code","source":"import transformers\nclassifier = transformers.pipeline('sentiment-analysis', model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n\nprint(classifier(\"BERT is amazing!\"))","metadata":{"id":"rP1KFtvLlJHR","colab":{"base_uri":"https://localhost:8080/","height":162,"referenced_widgets":["e85584c419aa445285eecb482778c7ba","5694548560b548dabed4b111766da60e","7fceb5ec7dec415a9dfcd4261aeb4a3d","1fd2361180bd49aa8e2012a5e379d0c1","77441a81d25c40819ae5af99ad70f3c8","48c3bc239f16407bbba2d36ac6e5aaae","5c87b856ffeb4c1dbf2d4637065d26ef","fbbe93e1d4a5493782b7a246f3cb1760","c3e31f6d90a84af08ee33023be184849","6099e17176dd4eef829ac7c45badc9e2","7ea9a125c76543419007fd5083ed63cd","b2786e8af69e490cba5048fca7a0a51e","f07e54fd856f4efc99bedb44abcece1b","e0d2ca01fd7042a88a5493323a61409c","e07d888d412d43f8ac4cc5285de07772","15227ca6cc5a4d219e0113da09926da4","cf83aaa31a1a47419db2127456beae69","1e463fce356b46859493cbd975163ef1","4ecb5a9efc3c42dd8faf4af9424ad5cf","3af4702b95484b8cabd891b18ffc71b1","e9210c257b8a4091b86123271c8a5486","7eb0bf256b8d4975b0615aa96f00bbe1","fc132bfb7d6447ad9900af7b80806aa1","ab6d124394214415a2580983c88bbb11","8578b4d2279f40dc846fcdfc2df55742","7213248ebe1f4e28a00a93eb33169170","b1497c0d7c3b4c04a91302a2cbc96db1","60e971374e5448d08e9698a5594ff60a","6c8113bb76024debaf3256431cbefe35","73d8ad019f044a6998e81273a922745a","a445a35355424cb0b4c7abf3d4e6f32d","d71a81e25f5b4f88b8361c62e2ab9f44","4f084bbe71bb433ba0e7ee50fccb71cc","5cff2bc12fec494e9e19b8a956186df6","787781c894bd46c6990f2513d9f2c79c","3f4eae6f79054676976f87b9524c4cf5","237d34743ee64428a9d22ee51e0423f3","b095428dcb8a4408854f854de54d5692","1b76512711884ffb81d3c3505b8fd137","2f53a3d1d0f44192beeb6ed8d40e762f","1b194af3033342b0b04dc12b3e055ff2","391b8f44109544328617fbc3a3c3b9fc","6f36db95f6fb4b4687c7130fc23c4348","82a35a7ae5e441a1b66534a3eab5e765"]},"outputId":"f4e9f426-6445-4d69-b7b7-dd083d7bdebf","execution":{"iopub.status.busy":"2024-03-04T07:29:43.612499Z","iopub.execute_input":"2024-03-04T07:29:43.612907Z","iopub.status.idle":"2024-03-04T07:30:04.774593Z","shell.execute_reply.started":"2024-03-04T07:29:43.612876Z","shell.execute_reply":"2024-03-04T07:30:04.773749Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-03-04 07:29:47.742379: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-04 07:29:47.742519: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-04 07:29:47.908820: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f10b033cda74bada3f8af0510bf06eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f61f42fc53c840b6956703fffa38f583"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d59c4173ab24f61bc2051a27be9b836"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff8b3dc849f44b1d870284a4635b03b5"}},"metadata":{}},{"name":"stdout","text":"[{'label': 'POSITIVE', 'score': 0.9998860359191895}]\n","output_type":"stream"}]},{"cell_type":"code","source":"outputs.values","metadata":{"execution":{"iopub.status.busy":"2024-03-04T07:30:15.104883Z","iopub.execute_input":"2024-03-04T07:30:15.105795Z","iopub.status.idle":"2024-03-04T07:30:15.112738Z","shell.execute_reply.started":"2024-03-04T07:30:15.105763Z","shell.execute_reply":"2024-03-04T07:30:15.111458Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<function dict.values>"},"metadata":{}}]},{"cell_type":"code","source":"import base64\ndata = {\n    'arryn': 'As High as Honor.',\n    'baratheon': 'Ours is the fury.',\n    'stark': 'Winter is coming.',\n    'tyrell': 'Growing strong.'\n}\n\n# YOUR CODE: predict sentiment for each noble house and create outputs dict\noutputs = {key: True if classifier(value)[0]['label'] == 'POSITIVE' else False for key, value in data.items()}\n#outputs = <YOUR CODE: dict (house name) : True if positive, False if negative>\n\nassert sum(outputs.values()) == 3 and outputs[base64.decodebytes(b'YmFyYXRoZW9u\\n').decode()] == False\nprint(\"Well done!\")","metadata":{"id":"nYUNuyXMn5l9","execution":{"iopub.status.busy":"2024-03-04T07:30:12.461048Z","iopub.execute_input":"2024-03-04T07:30:12.461449Z","iopub.status.idle":"2024-03-04T07:30:12.566328Z","shell.execute_reply.started":"2024-03-04T07:30:12.461406Z","shell.execute_reply":"2024-03-04T07:30:12.565538Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Well done!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You can also access vanilla Masked Language Model that was trained to predict masked words. Here's how:","metadata":{"id":"BRDhIH-XpSNo"}},{"cell_type":"code","source":"mlm_model = transformers.pipeline('fill-mask', model=\"bert-base-uncased\")\nMASK = mlm_model.tokenizer.mask_token\n\nfor hypo in mlm_model(f\"Donald {MASK} is the president of the united states.\"):\n  print(f\"P={hypo['score']:.5f}\", hypo['sequence'])","metadata":{"id":"pa-8noIllRbZ","execution":{"iopub.status.busy":"2024-03-04T07:30:18.903241Z","iopub.execute_input":"2024-03-04T07:30:18.903616Z","iopub.status.idle":"2024-03-04T07:30:22.674913Z","shell.execute_reply.started":"2024-03-04T07:30:18.903588Z","shell.execute_reply":"2024-03-04T07:30:22.673891Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b35c7a3769a422db4dd264de1b2a608"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df51ed20e20b47b58ca068d8fed20410"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0548b6359e8b4d18964b749500be9a9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7eb0399b074415888bb9921050d37f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58f7f91502394d9cbe655de09a1e6076"}},"metadata":{}},{"name":"stdout","text":"P=0.99719 donald trump is the president of the united states.\nP=0.00024 donald duck is the president of the united states.\nP=0.00022 donald ross is the president of the united states.\nP=0.00020 donald johnson is the president of the united states.\nP=0.00018 donald wilson is the president of the united states.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Your turn: use bert to recall what year was the Soviet Union founded in\nfor hypo in mlm_model(f\"The founding date of the Soviet Union is {MASK}.\"):\n  print(f\"P={hypo['score']:.5f}\", hypo['sequence'])","metadata":{"id":"9NxeG1Y5pwX1","execution":{"iopub.status.busy":"2024-03-04T07:30:30.206599Z","iopub.execute_input":"2024-03-04T07:30:30.207221Z","iopub.status.idle":"2024-03-04T07:30:30.276068Z","shell.execute_reply.started":"2024-03-04T07:30:30.207191Z","shell.execute_reply":"2024-03-04T07:30:30.274958Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"P=0.77394 the founding date of the soviet union is unknown.\nP=0.11223 the founding date of the soviet union is uncertain.\nP=0.04393 the founding date of the soviet union is disputed.\nP=0.02288 the founding date of the soviet union is unclear.\nP=0.01062 the founding date of the soviet union is debated.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"```\n\n```\n\n```\n\n```\n\n\nHuggingface offers hundreds of pre-trained models that specialize on different tasks. You can quickly find the model you need using [this list](https://huggingface.co/models).\n","metadata":{"id":"YJxRFzCSq903"}},{"cell_type":"code","source":"from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n\ntext = \"\"\"Almost two-thirds of the 1.5 million people who viewed this liveblog had Googled to discover\n the latest on the Rosetta mission. They were treated to this detailed account by the Guardian’s science editor,\n Ian Sample, and astronomy writer Stuart Clark of the moment scientists landed a robotic spacecraft on a comet\n for the first time in history, and the delirious reaction it provoked at their headquarters in Germany.\n  “We are there. We are sitting on the surface. Philae is talking to us,” said one scientist.\n\"\"\"\n\n# Task: create a pipeline for named entity recognition, use task name 'ner' and search for the right model in the list\n\ntokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\nmodel = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n\nner_model = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n\nnamed_entities = ner_model(text)","metadata":{"id":"HRux8Qp2hkXr","execution":{"iopub.status.busy":"2024-03-04T07:31:17.021400Z","iopub.execute_input":"2024-03-04T07:31:17.021829Z","iopub.status.idle":"2024-03-04T07:31:20.888239Z","shell.execute_reply.started":"2024-03-04T07:31:17.021798Z","shell.execute_reply":"2024-03-04T07:31:20.887286Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d1ae753e552446c98518c08aafb99bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62fef1a7601f4bc3bf1a4e381044a204"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"002942c217714cecae02e796355ff214"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06396131631f44199465822352e14b44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93d779aa227e471f945d0cb5676a49a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d606f9f8a385488e83cd8f83db8f5f44"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"print('OUTPUT:', named_entities)\nword_to_entity = {item['word']: item['entity'] for item in named_entities}\nassert 'org' in word_to_entity.get('Guardian').lower() and 'per' in word_to_entity.get('Stuart').lower()\nprint(\"All tests passed\")","metadata":{"id":"hf57MRzSiSON","execution":{"iopub.status.busy":"2024-03-04T07:31:23.032745Z","iopub.execute_input":"2024-03-04T07:31:23.033127Z","iopub.status.idle":"2024-03-04T07:31:23.039046Z","shell.execute_reply.started":"2024-03-04T07:31:23.033099Z","shell.execute_reply":"2024-03-04T07:31:23.038276Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"OUTPUT: [{'entity': 'B-LOC', 'score': 0.79910487, 'index': 27, 'word': 'Rose', 'start': 112, 'end': 116}, {'entity': 'I-LOC', 'score': 0.9511927, 'index': 28, 'word': '##tta', 'start': 116, 'end': 119}, {'entity': 'B-ORG', 'score': 0.998223, 'index': 40, 'word': 'Guardian', 'start': 179, 'end': 187}, {'entity': 'B-PER', 'score': 0.9997613, 'index': 46, 'word': 'Ian', 'start': 207, 'end': 210}, {'entity': 'I-PER', 'score': 0.99978715, 'index': 47, 'word': 'Sam', 'start': 211, 'end': 214}, {'entity': 'I-PER', 'score': 0.99964595, 'index': 48, 'word': '##ple', 'start': 214, 'end': 217}, {'entity': 'B-PER', 'score': 0.9997831, 'index': 53, 'word': 'Stuart', 'start': 240, 'end': 246}, {'entity': 'I-PER', 'score': 0.9997482, 'index': 54, 'word': 'Clark', 'start': 247, 'end': 252}, {'entity': 'B-LOC', 'score': 0.9997228, 'index': 85, 'word': 'Germany', 'start': 413, 'end': 420}, {'entity': 'B-PER', 'score': 0.9963127, 'index': 99, 'word': 'Phil', 'start': 470, 'end': 474}, {'entity': 'I-PER', 'score': 0.9889253, 'index': 100, 'word': '##ae', 'start': 474, 'end': 476}]\nAll tests passed\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### The building blocks of a pipeline\n\nHuggingface also allows you to access its pipelines on a lower level. There are two main abstractions for you:\n* `Tokenizer` - converts from strings to token ids and back\n* `Model` - a pytorch `nn.Module` with pre-trained weights\n\nYou can use such models as part of your regular pytorch code: insert is as a layer in your model, apply it to a batch of data, backpropagate, optimize, etc.","metadata":{"id":"ULMownz6sP9n"}},{"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased')\nmodel = transformers.AutoModel.from_pretrained('bert-base-uncased')\n","metadata":{"id":"KMJbV0QVsO0Q","execution":{"iopub.status.busy":"2024-03-04T07:32:42.708944Z","iopub.execute_input":"2024-03-04T07:32:42.709348Z","iopub.status.idle":"2024-03-04T07:32:43.402886Z","shell.execute_reply.started":"2024-03-04T07:32:42.709314Z","shell.execute_reply":"2024-03-04T07:32:43.401796Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokens_info.keys()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T07:36:31.154782Z","iopub.execute_input":"2024-03-04T07:36:31.155676Z","iopub.status.idle":"2024-03-04T07:36:31.161860Z","shell.execute_reply.started":"2024-03-04T07:36:31.155641Z","shell.execute_reply":"2024-03-04T07:36:31.160786Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"},"metadata":{}}]},{"cell_type":"code","source":"lines = [\n    \"Luke, I am your father.\",\n    \"Life is what happens when you're busy making other plans.\",\n    ]\n\n# tokenize a batch of inputs. \"pt\" means [p]y[t]orch tensors\ntokens_info = tokenizer(lines, padding=True, truncation=True, return_tensors=\"pt\")\n\nfor key in tokens_info:\n    print(key, tokens_info[key])\n\nprint(\"Detokenized:\")\nfor i in range(2):\n    print(tokenizer.decode(tokens_info['input_ids'][i]))","metadata":{"id":"ZgSPHKPRxG6U","execution":{"iopub.status.busy":"2024-03-04T07:35:15.153748Z","iopub.execute_input":"2024-03-04T07:35:15.154134Z","iopub.status.idle":"2024-03-04T07:35:15.163618Z","shell.execute_reply.started":"2024-03-04T07:35:15.154105Z","shell.execute_reply":"2024-03-04T07:35:15.162566Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"input_ids tensor([[ 101, 5355, 1010, 1045, 2572, 2115, 2269, 1012,  102,    0,    0,    0,\n            0,    0,    0],\n        [ 101, 2166, 2003, 2054, 6433, 2043, 2017, 1005, 2128, 5697, 2437, 2060,\n         3488, 1012,  102]])\ntoken_type_ids tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\nattention_mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\nDetokenized:\n[CLS] luke, i am your father. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n[CLS] life is what happens when you're busy making other plans. [SEP]\n","output_type":"stream"}]},{"cell_type":"code","source":"out['pooler_output'].shape","metadata":{"execution":{"iopub.status.busy":"2024-03-04T07:47:20.690653Z","iopub.execute_input":"2024-03-04T07:47:20.691736Z","iopub.status.idle":"2024-03-04T07:47:20.698088Z","shell.execute_reply.started":"2024-03-04T07:47:20.691700Z","shell.execute_reply":"2024-03-04T07:47:20.696880Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 768])"},"metadata":{}}]},{"cell_type":"code","source":"# You can now apply the model to get embeddings\nwith torch.no_grad():\n    out = model(**tokens_info)\n\nprint(out['pooler_output'])","metadata":{"id":"MJkbHxERyfL4","execution":{"iopub.status.busy":"2024-03-04T07:44:56.819691Z","iopub.execute_input":"2024-03-04T07:44:56.820113Z","iopub.status.idle":"2024-03-04T07:44:56.965523Z","shell.execute_reply.started":"2024-03-04T07:44:56.820079Z","shell.execute_reply":"2024-03-04T07:44:56.962919Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"tensor([[-0.8854, -0.4722, -0.9392,  ..., -0.8081, -0.6955,  0.8748],\n        [-0.9297, -0.5161, -0.9334,  ..., -0.9017, -0.7492,  0.9201]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Transformers knowledge hub: https://huggingface.co/transformers/","metadata":{"id":"_Vij7Gc1wOaq"}},{"cell_type":"markdown","source":"### Build-a-transformer (2 points)\n\nIn this section, you will implement a transformer language model layer by layer, then use it to generate (hopefully) coherent text.\n\nTo understand how these layers work, please check out our guide to transformers from [nlp course for you -> transformers](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html#transformer_intro).\n\n\nFirst, we download pre-trained weights for the [GPT2 model by OpenAI](https://openai.com/research/better-language-models) - a prominent model from 2019.\n\n\n\nIdea & code by: Ilya Beletsky","metadata":{"id":"bwmTTyjUGqol"}},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nstate_dict = torch.load(hf_hub_download(\"gpt2\", filename=\"pytorch_model.bin\"))\nfor key, value in tuple(state_dict.items()):\n    if key.startswith('h.') and key.endswith('.weight') and value.ndim == 2:\n        value.transpose_(1, 0)  # <-- for compatibility with modern PyTorch modules\n    if key.startswith('h.') and key.endswith('.attn.bias') and value.ndim == 4:\n        state_dict.pop(key)  # <-- triangular binar masks, not needed in this code\n\nprint('Weights:', repr(sorted(state_dict.keys()))[:320], '...')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vOcK0lGTGqol","outputId":"131fbc38-d4af-4e3b-b87b-f4c1b15d3162","execution":{"iopub.status.busy":"2024-03-04T08:00:36.907139Z","iopub.execute_input":"2024-03-04T08:00:36.907578Z","iopub.status.idle":"2024-03-04T08:00:40.647478Z","shell.execute_reply.started":"2024-03-04T08:00:36.907544Z","shell.execute_reply":"2024-03-04T08:00:40.646405Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2ed974562b94fb9805fe4a90208f104"}},"metadata":{}},{"name":"stdout","text":"Weights: ['h.0.attn.c_attn.bias', 'h.0.attn.c_attn.weight', 'h.0.attn.c_proj.bias', 'h.0.attn.c_proj.weight', 'h.0.ln_1.bias', 'h.0.ln_1.weight', 'h.0.ln_2.bias', 'h.0.ln_2.weight', 'h.0.mlp.c_fc.bias', 'h.0.mlp.c_fc.weight', 'h.0.mlp.c_proj.bias', 'h.0.mlp.c_proj.weight', 'h.1.attn.c_attn.bias', 'h.1.attn.c_attn.weight', 'h.1. ...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In the next few cells, we shall implement the model layer by layer to make use of those weights.\n\nAs you might recall, transformers contain two main layer types: attention and fully-connected layers.\n\nThe fully connected layers are by far easier to understand, so we shall begin there:\n\nPlease implement fully-connected layer __without residual or layer normalization__ (we'll add those in a bit).","metadata":{"id":"mr0SUtQnGqom"}},{"cell_type":"code","source":"class GeLUThatWasUsedInGPT2(nn.Module):\n    def forward(self, x):\n        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * x ** 3)))\n\nclass FullyConnected(nn.Module):\n    def __init__(self, dim: int):\n        super().__init__()\n        self.c_fc = nn.Linear(dim, 4  * dim)\n        self.gelu = GeLUThatWasUsedInGPT2()\n        self.c_proj = nn.Linear(4 * dim, dim)\n\n    def forward(self, x):\n        # x.shape = [batch_size, seq_length, dim]\n        out = self.c_fc(x)\n        out = self.gelu(out)\n        out = self.c_proj(out)\n        return out\n","metadata":{"id":"3Rh-6DX9Gqom","execution":{"iopub.status.busy":"2024-03-04T08:08:03.596096Z","iopub.execute_input":"2024-03-04T08:08:03.596525Z","iopub.status.idle":"2024-03-04T08:08:03.605113Z","shell.execute_reply.started":"2024-03-04T08:08:03.596495Z","shell.execute_reply":"2024-03-04T08:08:03.603793Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Now, let's test that it works with GPT-2 weights:","metadata":{"id":"iSVGKnHBGqom"}},{"cell_type":"code","source":"mlp = FullyConnected(dim=768)\nmlp.load_state_dict({'c_fc.weight': state_dict['h.0.mlp.c_fc.weight'],\n                     'c_fc.bias': state_dict['h.0.mlp.c_fc.bias'],\n                     'c_proj.weight': state_dict['h.0.mlp.c_proj.weight'],\n                     'c_proj.bias': state_dict['h.0.mlp.c_proj.bias']})\n\ntorch.manual_seed(1337)\nx = torch.randn(1, 2, 768)  # [batch_size, sequence_length, dim]\nchecksum = torch.sum(mlp(x) * x)\nassert abs(checksum.item() - 1282.3315) < 0.1, \"layer outputs do not match reference\"\nassert torch.allclose(mlp(x[:, (1, 0), :])[:, (1, 0), :], mlp(x)), \"mlp must be permutation-invariant\"\nprint(\"Seems legit!\")","metadata":{"id":"CoWjZwZkGqom","execution":{"iopub.status.busy":"2024-03-04T08:31:28.079380Z","iopub.execute_input":"2024-03-04T08:31:28.079792Z","iopub.status.idle":"2024-03-04T08:31:28.164983Z","shell.execute_reply.started":"2024-03-04T08:31:28.079760Z","shell.execute_reply":"2024-03-04T08:31:28.164003Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Seems legit!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now, let's get to attention layers.\n\nSince GPT-2 needs to generate text from left to right, each generated token can only attend to tokens on the left (and itself). This kid of attention is called \"Masked\" self-attention, because it hides tokens to the right.\n\nAs before, please implement masked self-attention __without layernorm or residual connections.__","metadata":{"id":"VbfCevRwGqom"}},{"cell_type":"code","source":"class MaskedSelfAttention(nn.Module):\n    def __init__(self, dim: int, num_heads: int):\n        super().__init__()\n        self.c_attn = nn.Linear(dim, dim * 3)  # query + key + value, combined\n        self.c_proj = nn.Linear(dim, dim)  # output projection\n        self.dim, self.num_heads = dim, num_heads\n        self.head_size = dim // num_heads\n\n    def forward(self, x):\n        q, k, v = self.c_attn(x).split(dim=-1, split_size=self.dim)\n        assert q.shape == k.shape == v.shape == x.shape, \"q, k and v must have the same shape as x\"\n\n\n        # Note: this is an inefficient implementation that uses a for-loop.\n        # For bonus points, re-write the attention code below manually, with the following constrains:\n        # 1) do not use for-loops (or other loops). Compute everything in parallel with vectorized operations\n        # 2) do not use F.scaled_dot_product_attention - write your own attention code using basic PyTorch ops\n        head_outputs = []\n        for head_index in range(self.num_heads):\n            head_selector = range(self.head_size * head_index, self.head_size * (head_index + 1))\n\n            head_queries = q[..., head_selector]\n            head_keys = k[..., head_selector]\n            head_values = v[..., head_selector]\n\n            single_head_output = F.scaled_dot_product_attention(\n                head_queries, head_keys, head_values,\n                is_causal=True)\n            # docs: https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n            head_outputs.append(single_head_output)\n\n        combined_head_outputs = torch.cat(head_outputs, dim=-1)\n        return self.c_proj(combined_head_outputs)\n","metadata":{"id":"T6j7M4hLGqon","execution":{"iopub.status.busy":"2024-03-04T08:26:27.141511Z","iopub.execute_input":"2024-03-04T08:26:27.141939Z","iopub.status.idle":"2024-03-04T08:26:27.154386Z","shell.execute_reply.started":"2024-03-04T08:26:27.141903Z","shell.execute_reply":"2024-03-04T08:26:27.152707Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Test that it works","metadata":{"id":"umZpcpIkJva7"}},{"cell_type":"code","source":"attn = MaskedSelfAttention(dim=768, num_heads=12)\nattn.load_state_dict({'c_attn.weight': state_dict['h.0.attn.c_attn.weight'],\n                      'c_attn.bias': state_dict['h.0.attn.c_attn.bias'],\n                      'c_proj.weight': state_dict['h.0.attn.c_proj.weight'],\n                      'c_proj.bias': state_dict['h.0.attn.c_proj.bias']})\n\ntorch.manual_seed(1337)\nx = torch.randn(1, 10, 768)  # [batch_size, sequence_length, dim]\nchecksum = torch.sum(attn(x) * x)\nassert abs(checksum.item() - 2703.6772) < 0.1, \"layer outputs do not match reference\"\nassert not torch.allclose(attn(x[:, (1, 0), :])[:, (1, 0), :], attn(x[:, (0, 1), :])), \"masked attention must *not* be permutation-invariant\"\nprint(\"It works!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tg5Oj_PPM6hj","outputId":"ebeddb50-d805-47ae-cc3a-4d68d900b3a3","execution":{"iopub.status.busy":"2024-03-04T08:31:37.144601Z","iopub.execute_input":"2024-03-04T08:31:37.144978Z","iopub.status.idle":"2024-03-04T08:31:37.198147Z","shell.execute_reply.started":"2024-03-04T08:31:37.144951Z","shell.execute_reply":"2024-03-04T08:31:37.196928Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"It works!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We can now combine attention and MLP to build the full transformer layer:\n\n![img](https://i.imgur.com/1sq2vHO.png)","metadata":{"id":"rn6tgTHzOK4l"}},{"cell_type":"code","source":"class TransformerLayer(nn.Module):\n    def __init__(self, dim: int, num_heads: int):\n        super().__init__()\n        self.ln_1 = nn.LayerNorm(dim)\n        self.attn = MaskedSelfAttention(dim, num_heads)\n        self.ln_2 = nn.LayerNorm(dim)\n        self.mlp = FullyConnected(dim)\n\n    def forward(self, x):\n        \n        out = self.attn(self.ln_1(x))\n        \n        out = out + x # residual1\n        out2 = self.mlp(self.ln_2(out))\n        result_output = out + out2 # residual2\n        \n        return result_output","metadata":{"id":"p3AH7YQvRpvU","execution":{"iopub.status.busy":"2024-03-04T08:35:48.808358Z","iopub.execute_input":"2024-03-04T08:35:48.808776Z","iopub.status.idle":"2024-03-04T08:35:48.816331Z","shell.execute_reply.started":"2024-03-04T08:35:48.808745Z","shell.execute_reply":"2024-03-04T08:35:48.815088Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"layer = TransformerLayer(dim=768, num_heads=12)\nlayer.load_state_dict({k[5:]: v for k, v in state_dict.items() if k.startswith('h.10.')})\nassert abs(torch.sum(layer(x) * x).item() - 9874.7383) < 0.1\nprint(\"Good job!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qzo_QeFVSNZa","outputId":"15613968-b4d7-4391-dfff-3b490951a125","execution":{"iopub.status.busy":"2024-03-04T08:35:52.575988Z","iopub.execute_input":"2024-03-04T08:35:52.576383Z","iopub.status.idle":"2024-03-04T08:35:52.692833Z","shell.execute_reply.started":"2024-03-04T08:35:52.576351Z","shell.execute_reply":"2024-03-04T08:35:52.689973Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Good job!\n","output_type":"stream"}]},{"cell_type":"code","source":"nn.Embedding(50257, 768).weight.T.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-04T08:53:52.019880Z","iopub.execute_input":"2024-03-04T08:53:52.020271Z","iopub.status.idle":"2024-03-04T08:53:52.464819Z","shell.execute_reply.started":"2024-03-04T08:53:52.020243Z","shell.execute_reply":"2024-03-04T08:53:52.463585Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"torch.Size([768, 50257])"},"metadata":{}}]},{"cell_type":"code","source":"class GPT2(nn.Module):\n    def __init__(self, vocab_size: int, dim: int, num_heads: int, num_layers: int, max_position_embeddings: int = 1024):\n        super().__init__()\n        self.wte = nn.Embedding(vocab_size, dim)  # token embeddings\n        self.wpe = nn.Embedding(max_position_embeddings, dim)  # position embeddings\n        self.ln_f = nn.LayerNorm(dim)   # final layer norm - goes after all transformer layers, but before logits\n\n        self.h = nn.Sequential(*(TransformerLayer(dim, num_heads) for layer in range(num_layers)))\n\n    def forward(self, input_ids):\n        # input_ids.shape: [batch_size, sequence_length], int64 token ids\n        position_ids = torch.arange(input_ids.shape[1], device=input_ids.device).unsqueeze(0)\n\n        token_embeddings = self.wte(input_ids)\n        position_embeddings = self.wpe(position_ids)\n        full_embeddings = token_embeddings + position_embeddings\n\n        transformer_output = self.h(full_embeddings)\n        transformer_output_ln = self.ln_f(transformer_output)\n\n        # final layer: we predict logits by re-using token embeddings as linear weights\n        output_logits = transformer_output_ln @ self.wte.weight.T\n        return output_logits\n","metadata":{"id":"Mbqw9iuaSrYy","execution":{"iopub.status.busy":"2024-03-04T08:58:02.461287Z","iopub.execute_input":"2024-03-04T08:58:02.462391Z","iopub.status.idle":"2024-03-04T08:58:02.472120Z","shell.execute_reply.started":"2024-03-04T08:58:02.462341Z","shell.execute_reply":"2024-03-04T08:58:02.470886Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"predicted_logits[:, -1].shape","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:01:22.640479Z","iopub.execute_input":"2024-03-04T09:01:22.640947Z","iopub.status.idle":"2024-03-04T09:01:22.650915Z","shell.execute_reply.started":"2024-03-04T09:01:22.640910Z","shell.execute_reply":"2024-03-04T09:01:22.649103Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 50257])"},"metadata":{}}]},{"cell_type":"code","source":"input_ids.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:00:41.072486Z","iopub.execute_input":"2024-03-04T09:00:41.072893Z","iopub.status.idle":"2024-03-04T09:00:41.080220Z","shell.execute_reply.started":"2024-03-04T09:00:41.072863Z","shell.execute_reply":"2024-03-04T09:00:41.078929Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 2])"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2', add_prefix_space=True)\nmodel = GPT2(vocab_size=50257, dim=768, num_heads=12, num_layers=12)\nmodel.load_state_dict(state_dict)\n\ninput_ids = tokenizer(\"A quick\", return_tensors='pt')['input_ids']\n\npredicted_logits = model(input_ids)\nmost_likely_token_id = predicted_logits[:, -1].argmax().item()\n\nprint(\"Prediction:\", tokenizer.decode(most_likely_token_id))","metadata":{"id":"p0m8jt66aDIh","execution":{"iopub.status.busy":"2024-03-04T08:59:47.791814Z","iopub.execute_input":"2024-03-04T08:59:47.792312Z","iopub.status.idle":"2024-03-04T09:00:01.116633Z","shell.execute_reply.started":"2024-03-04T08:59:47.792277Z","shell.execute_reply":"2024-03-04T09:00:01.115484Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39e5ec15d67c467599609697f3100bfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a944b68a36241a3813dce62073ed506"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61386080186b478a8423e0271f3bd9b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39c8d0ed213a48669c545d1e7edbfa31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0d82796f98343f283626460b35a2e4c"}},"metadata":{}},{"name":"stdout","text":"Prediction:  look\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"The Fermi paradox \"\ntokens = tokenizer.encode(text)\nprint(end=tokenizer.decode(tokens))\nline_length = len(tokenizer.decode(tokens))\n\nfor i in range(500):\n    # Predict logits with your model\n    with torch.no_grad():\n        logits = model(torch.as_tensor([tokens]))\n\n    # Sample with probabilities\n    p_next = torch.softmax(logits[0, -1, :], dim=-1).data.cpu().numpy()\n    next_token_index = np.random.choice(len(p_next), p=p_next)\n\n    tokens.append(int(next_token_index))\n    print(end=tokenizer.decode(tokens[-1]))\n    line_length += len(tokenizer.decode(tokens[-1]))\n    if line_length > 120:\n      line_length = 0\n      print()\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8ql3Lo7dXZ2","outputId":"8db86d13-d16b-4f97-db87-0385c0d91426","execution":{"iopub.status.busy":"2024-03-04T09:03:56.497216Z","iopub.execute_input":"2024-03-04T09:03:56.497630Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":" The Fermi paradox  is captured perfectly: in equilibrium, the natural order of things is generated at the maximum rate of\n entropy (although sequentially priced by an inflationary process). This assumes that all computations from the first five\n classical revolutions cease and a non-quotable status quo is established, where the policy of the climate has force to keep\n pace pace","output_type":"stream"}]},{"cell_type":"markdown","source":"```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n\n### Here's how you can do the same with transformers library","metadata":{"id":"V3NJ0ocgGqop"}},{"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2', add_prefix_space=True)\nmodel = transformers.AutoModelForCausalLM.from_pretrained('gpt2')\nprint('Generated text:', tokenizer.decode(\n    model.generate(\n        **tokenizer(\"The Fermi paradox \", return_tensors='pt'),\n        do_sample=True, max_new_tokens=50\n    ).flatten().numpy()\n))\n","metadata":{"id":"NTOHu124Gqop","outputId":"5bb38785-a7d9-47e1-a887-c03634945c0b"},"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"Generated continuation:  The Fermi paradox  (with its paradoxical consequences which, if any, may also be taken to be the paradox of the Big Bang. If an explosion can only happen after the collapse of the matter in one of three states  or after the collapse of a\n"}]}]}